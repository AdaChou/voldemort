package voldemort.client.rebalance;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.Set;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.atomic.AtomicInteger;

import com.google.common.collect.Sets;
import joptsimple.OptionParser;
import joptsimple.OptionSet;

import org.apache.log4j.Logger;

import voldemort.VoldemortException;
import voldemort.client.protocol.admin.AdminClient;
import voldemort.cluster.Cluster;
import voldemort.server.VoldemortConfig;
import voldemort.server.protocol.admin.AsyncOperationStatus;
import voldemort.store.StoreDefinition;
import voldemort.store.metadata.MetadataStore;
import voldemort.store.metadata.MetadataStore.VoldemortState;
import voldemort.utils.CmdUtils;
import voldemort.utils.Pair;
import voldemort.utils.RebalanceUtils;
import voldemort.utils.Time;
import voldemort.utils.Utils;
import voldemort.versioning.VectorClock;
import voldemort.versioning.Versioned;
import voldemort.xml.ClusterMapper;
import voldemort.xml.StoreDefinitionsMapper;

import com.google.common.base.Joiner;
import com.google.common.collect.Lists;
import com.google.common.collect.Maps;

public class MigratePartitions {

    private static Logger logger = Logger.getLogger(MigratePartitions.class);
    private final AdminClient adminClient;
    private final List<String> storeNames;
    private List<Integer> stealerNodeIds;
    private final VoldemortConfig voldemortConfig;
    private final HashMap<Integer, RebalanceNodePlan> stealerNodePlans;
    private final HashMap<Integer, List<RebalancePartitionsInfo>> donorNodePlans;
    private final HashMap<Integer, Versioned<String>> donorStates;
    private final boolean transitionToNormal;
    private boolean simulation = false;
    private final int parallelism;
    private final ExecutorService executor;

    public MigratePartitions(Cluster currentCluster,
                             Cluster targetCluster,
                             List<StoreDefinition> currentStoreDefs,
                             List<StoreDefinition> targetStoreDefs,
                             AdminClient adminClient,
                             VoldemortConfig voldemortConfig,
                             List<Integer> stealerNodeIds,
                             int parallelism,
                             boolean transitionToNormal,
                             boolean simulation) {

        this(currentCluster,
             targetCluster,
             currentStoreDefs,
             targetStoreDefs,
             adminClient,
             voldemortConfig,
             stealerNodeIds,
             parallelism,
             transitionToNormal);
        this.simulation = simulation;
    }

    /**
     * 
     * @param currentCluster The cluster as it is now
     * @param targetCluster The cluster as we would want in the future
     * @param currentStoreDefs The current list of store definitions
     * @param targetStoreDefs The final list of store definitions
     * @param adminClient Admin client which we'll use to query
     * @param voldemortConfig Voldemort configurations
     * @param stealerNodeIds The list of stealer nodes we'll work on. If null is
     *        sent will work on all generated by plan
     * @param transitionToNormal After the complete migration of partitions, do
     *        you want to transition back to normal state?
     */
    public MigratePartitions(Cluster currentCluster,
                             Cluster targetCluster,
                             List<StoreDefinition> currentStoreDefs,
                             List<StoreDefinition> targetStoreDefs,
                             AdminClient adminClient,
                             VoldemortConfig voldemortConfig,
                             List<Integer> stealerNodeIds,
                             int parallelism,
                             boolean transitionToNormal) {
        this.adminClient = Utils.notNull(adminClient);
        this.stealerNodeIds = stealerNodeIds;
        this.voldemortConfig = Utils.notNull(voldemortConfig);
        this.transitionToNormal = transitionToNormal;
        this.parallelism = parallelism;
        this.executor = Executors.newFixedThreadPool(parallelism);
        MigratePartitionsPlan plan = new MigratePartitionsPlan(currentCluster,
                                                               targetCluster,
                                                               currentStoreDefs,
                                                               targetStoreDefs);

        logger.info("Rebalance cluster plan => " + plan);

        this.stealerNodePlans = plan.getRebalancingTaskQueuePerNode();
        if(this.stealerNodeIds == null) {
            this.stealerNodeIds = Lists.newArrayList(stealerNodePlans.keySet());
        }

        this.storeNames = RebalanceUtils.getStoreNames(targetStoreDefs);

        // Converts the stealer node plans into a mapping of plans on a per
        // donor node basis. This is required for each donor node to know which
        // partitions are being grandfathered.
        this.donorNodePlans = Maps.newHashMap();
        for(int stealerNodeId: this.stealerNodeIds) {
            RebalanceNodePlan nodePlan = this.stealerNodePlans.get(stealerNodeId);
            if(nodePlan == null)
                continue;
            for(RebalancePartitionsInfo info: nodePlan.getRebalanceTaskList()) {
                List<RebalancePartitionsInfo> donorPlan = donorNodePlans.get(info.getDonorId());
                if(donorPlan == null) {
                    donorPlan = Lists.newArrayList();
                    donorNodePlans.put(info.getDonorId(), donorPlan);
                }
                donorPlan.add(info);
            }
        }
        this.donorStates = Maps.newHashMap();

        for(int donorNodeId: donorNodePlans.keySet()) {
            logger.info("Plan for donor node id " + donorNodeId + " => ");
            List<RebalancePartitionsInfo> list = donorNodePlans.get(donorNodeId);
            for(RebalancePartitionsInfo stealInfo: list) {
                logger.info(stealInfo);
            }
            logger.info("===============================================");
        }
    }

    /**
     * @return Map of donor node id to their corresponding list of rebalance
     *         info per partition
     */
    public HashMap<Integer, List<RebalancePartitionsInfo>> getDonorNodePlan() {
        return donorNodePlans;
    }

    /**
     * Update the state of all donor nodes to grandfather state
     * 
     */
    public void changeToGrandfather() {
        for(int donorNodeId: donorNodePlans.keySet()) {
            logger.info("Transitioning " + donorNodeId + " to grandfathering state");
            if(!simulation) {
                Versioned<String> serverState = adminClient.updateGrandfatherMetadata(donorNodeId,
                                                                                      donorNodePlans.get(donorNodeId));
                if(!VoldemortState.valueOf(serverState.getValue())
                                  .equals(MetadataStore.VoldemortState.GRANDFATHERING_SERVER)) {
                    throw new VoldemortException("Node "
                                                 + donorNodeId
                                                 + " is not in normal state to perform grandfathering");
                }
                donorStates.put(donorNodeId, serverState);
            }
            logger.info("Successfully transitioned " + donorNodeId + " to grandfathering state");
        }
    }

    /**
     * Update the state of all donor nodes in grandfathering state back to
     * normal
     * 
     */
    public void changeToNormal() {
        for(int donorNodeId: donorStates.keySet()) {
            logger.info("Rolling back state of " + donorNodeId + " to normal");
            try {
                VectorClock clock = (VectorClock) donorStates.get(donorNodeId).getVersion();
                adminClient.updateRemoteMetadata(donorNodeId,
                                                 MetadataStore.SERVER_STATE_KEY,
                                                 Versioned.value(MetadataStore.VoldemortState.NORMAL_SERVER.toString(),
                                                                 clock.incremented(donorNodeId,
                                                                                   System.currentTimeMillis())));
            } catch(Exception e) {
                logger.error("Rolling back state for " + donorNodeId + " failed");
            }
        }
    }

    public void migrate() {

        if(donorNodePlans.size() == 0) {
            logger.info("Nothing to move around");
            return;
        }
        /**
         * Lets move all the donor nodes into grandfathering state. First
         * generate all donor node ids and corresponding migration plans
         */
        logger.info("Changing state of donor nodes " + donorNodePlans.keySet());
        int i = 0;
        for(Map.Entry<Integer, RebalanceNodePlan> entry: stealerNodePlans.entrySet()) {
            i += entry.getValue().getRebalanceTaskList().size();
        }
        final int total = i * storeNames.size();
        final AtomicInteger completed = new AtomicInteger(0);
        final long startTime = System.currentTimeMillis();
        logger.info("================ There are " + total + " tasks to do! ============== ");
        try {
            changeToGrandfather();

            /**
             * Do all the stealer nodes sequentially, while each store can be
             * done in parallel for all the respective donor nodes
             */
            final CountDownLatch latch = new CountDownLatch(stealerNodeIds.size());
            for(final int stealerNodeId: stealerNodeIds) {
                executor.submit(new Runnable() {
                    public void run() {
                        try {
                            RebalanceNodePlan nodePlan = stealerNodePlans.get(stealerNodeId);
                            if(nodePlan == null) {
                                logger.info("No plan for stealer node id " + stealerNodeId);
                                return;
                            }
                            List<RebalancePartitionsInfo> partitionInfo = nodePlan.getRebalanceTaskList();

                            logger.info("Working on stealer node id " + stealerNodeId);
                            for(String storeName: storeNames) {
                                logger.info("- Working on store " + storeName);

                                HashMap<Integer, Integer> nodeIdToRequestId = Maps.newHashMap();
                                Set<Pair<Integer, Integer>> pending = Sets.newHashSet();
                                for(RebalancePartitionsInfo r: partitionInfo) {
                                    logger.info("-- Started migration for donor node id " + r);
                                    if(!simulation) {
                                        int attemptId = adminClient.migratePartitions(r.getDonorId(),
                                                                                  stealerNodeId,
                                                                                  storeName,
                                                                                  r.getPartitionList(),
                                                                                  null);
                                        nodeIdToRequestId.put(r.getDonorId(),
                                                              attemptId);
                                        pending.add(Pair.create(r.getDonorId(), attemptId));
                                    }

                                }

                                // Now that we started parallel migration for one store,
                                // wait for it to complete

                                while(!pending.isEmpty()) {
                                    for(int nodeId: nodeIdToRequestId.keySet()) {
                                        Integer attemptId = nodeIdToRequestId.get(nodeId);
                                        AsyncOperationStatus status = adminClient.getAsyncRequestStatus(stealerNodeId,
                                                                                                        attemptId);
                                        logger.info("Status from node " + nodeId + " (" + status.getDescription() + ") - "
                                                    + status.getStatus());
                                        if(status.isComplete()) {
                                            if(pending.contains(Pair.create(nodeId, attemptId))) {
                                                logger.info("-- Completed migration from "
                                                            + nodeId + " to "+
                                                            + stealerNodeId);
                                                pending.remove(Pair.create(nodeId, attemptId));
                                                logger.info("Finished " + completed.incrementAndGet() + " out of " + total + " tasks");
                                                long msPerMigration = (System.currentTimeMillis() - startTime) / completed.get();
                                                long etaSeconds = (total - completed.get()) * msPerMigration / Time.MS_PER_SECOND;
                                                logger.info("Current velocity " + msPerMigration / Time.MS_PER_SECOND + " seconds for each task");
                                                logger.info("Time until finished " + etaSeconds + " seconds");
                                            }
                                            if(pending.isEmpty())
                                                break;
                                        }
                                        try {
                                            Thread.sleep(30000);
                                        } catch(InterruptedException e) {
                                            logger.error(e, e);
                                            throw new VoldemortException(e);
                                        }
                                    }
                                }
                            }
                            logger.info("Finished migrating to " + stealerNodeId);
                            logger.info("===============================================");
                        } finally {
                            latch.countDown();
                        }
                    }
                });
            }
            try {
                latch.await();
            } catch(InterruptedException e) {
                e.printStackTrace();
            }
        } finally {

            // Move all nodes in grandfathered state back to normal
            if(donorStates != null && transitionToNormal) {
                changeToNormal();
            }
            executor.shutdown();
        }
    }

    public static void main(String[] args) throws IOException {

        OptionParser parser = new OptionParser();
        parser.accepts("help", "print help information");
        parser.accepts("parallelism", "Parallelism [Default 2]")
              .withRequiredArg()
              .describedAs("parallelism")
              .ofType(Integer.class);
        parser.accepts("target-cluster-xml", "[REQUIRED] target cluster xml file location")
              .withRequiredArg()
              .describedAs("path");
        parser.accepts("stores-xml", "[REQUIRED] stores xml file location")
              .withRequiredArg()
              .describedAs("path");
        parser.accepts("target-stores-xml", "stores xml file location if changed")
              .withRequiredArg()
              .describedAs("path");
        parser.accepts("cluster-xml", "[REQUIRED] cluster xml file location")
              .withRequiredArg()
              .describedAs("path");
        parser.accepts("stealer-node-ids", "Comma separated node ids [Default - all]")
              .withRequiredArg()
              .ofType(Integer.class)
              .withValuesSeparatedBy(',');
        parser.accepts("transition-to-normal",
                       "At the end of migration do we want to transition back to normal state? [Default-false]");
        parser.accepts("simulation", "Run the full process as simulation");

        OptionSet options = parser.parse(args);

        if(options.has("help")) {
            parser.printHelpOn(System.out);
            System.exit(0);
        }

        Set<String> missing = CmdUtils.missing(options,
                                               "cluster-xml",
                                               "stores-xml",
                                               "target-cluster-xml");
        if(missing.size() > 0) {
            System.err.println("Missing required arguments: " + Joiner.on(", ").join(missing));
            parser.printHelpOn(System.err);
            System.exit(1);
        }

        String targetClusterFile = (String) options.valueOf("target-cluster-xml");
        String currentClusterFile = (String) options.valueOf("cluster-xml");
        String currentStoresFile = (String) options.valueOf("stores-xml");
        String targetStoresFile = currentStoresFile;
        int parallelism = CmdUtils.valueOf(options, "parallelism", 2);
        boolean transitionToNormal = options.has("transition-to-normal");
        boolean simulation = options.has("simulation");

        if(options.has("target-stores-xml")) {
            targetStoresFile = (String) options.valueOf("target-stores-xml");
        }

        if(!Utils.isReadableFile(targetClusterFile) || !Utils.isReadableFile(currentClusterFile)
           || !Utils.isReadableFile(currentStoresFile) || !Utils.isReadableFile(targetStoresFile)) {
            System.err.println("Could not read metadata files from path provided");
            parser.printHelpOn(System.err);
            System.exit(1);
        }

        List<Integer> stealerNodeIds = null;
        if(options.has("stealer-node-ids")) {
            stealerNodeIds = Utils.uncheckedCast(options.valueOf("stealer-node-ids"));
        }

        AdminClient adminClient = null;
        try {
            VoldemortConfig voldemortConfig = createTempVoldemortConfig();
            Cluster currentCluster = new ClusterMapper().readCluster(new BufferedReader(new FileReader(currentClusterFile)));
            Cluster targetCluster = new ClusterMapper().readCluster(new BufferedReader(new FileReader(targetClusterFile)));
            adminClient = RebalanceUtils.createTempAdminClient(voldemortConfig,
                                                               currentCluster,
                                                               targetCluster.getNumberOfNodes(),
                                                               1);

            List<StoreDefinition> currentStoreDefs = new StoreDefinitionsMapper().readStoreList(new BufferedReader(new FileReader(currentStoresFile)));
            List<StoreDefinition> targetStoreDefs = new StoreDefinitionsMapper().readStoreList(new BufferedReader(new FileReader(targetStoresFile)));

            MigratePartitions migratePartitions = new MigratePartitions(currentCluster,
                                                                        targetCluster,
                                                                        currentStoreDefs,
                                                                        targetStoreDefs,
                                                                        adminClient,
                                                                        voldemortConfig,
                                                                        stealerNodeIds,
                                                                        parallelism,
                                                                        transitionToNormal,
                                                                        simulation);

            migratePartitions.migrate();
        } catch(Exception e) {
            logger.error("Error in migrate partitions", e);
        } finally {
            if(adminClient != null)
                adminClient.stop();
        }
    }

    public static VoldemortConfig createTempVoldemortConfig() {
        File temp = new File(System.getProperty("java.io.tmpdir"),
                             Integer.toString(new Random().nextInt()));
        temp.delete();
        temp.mkdir();
        temp.deleteOnExit();
        VoldemortConfig config = new VoldemortConfig(0, temp.getAbsolutePath());
        new File(config.getMetadataDirectory()).mkdir();
        return config;
    }
}
